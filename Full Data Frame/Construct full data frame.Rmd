---
title: "Load data -> join"
output: html_document
---

## 1. Load packages
```{r}
library(tidyr)
library(dplyr)
library(sf)
library(stringr)
library(data.table)
library(lwgeom)

datanames <- c("gisimpcop", "impsegcop", "gispropcop", "allpropcop", "segchar", "rollhist", "impseg", "salescop","school", "imps", "constraints", "rollhist_wide", "taxlots", "footprints")
datanames

# Set working directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
```

## 2. Set pathnames and load databases
```{r}
# The geodatabase Nick sent via email on 10/29
gdb <- "./DATA/data2.gdb"


capacity0 <- st_read(gdb, layer = "bli_development_capacity")
gisimpcop <- st_read(gdb, layer = "CoP_GISImprovement")
impsegcop <- st_read(gdb, layer = "CoP_OrionImprovementSegment")
#gispropcop <- st_read(gdb, layer = "CoP_GISProperty")
#allpropcop <- st_read(gdb, layer = "CoP_AllProperties")
#segchar <- st_read(gdb, layer = "Seg_Char")
#rollhist <- st_read(gdb, layer = "roll_history")
#rollhist_wide <- st_read(gdb, layer = "roll_history_wide")
#rollvals <- st_read(gdb, layer = "roll_values")
impseg <- st_read(gdb, layer = "imp_segments")
#salescop <- st_read(gdb, layer = "CoP_OrionSalesHistory")
school <- st_read(gdb, layer = "school_attendance_areas")
#imps <- st_read(gdb, layer = "improvements")

firelu <- st_read(gdb, layer = "Fireplace_Lookup")
segmentlu <- st_read(gdb, layer = "Segment_Type_Lookup")
imptypelu <- st_read(gdb, layer = "Imp_Type_Lookup")
impcodeslu <- st_read(gdb, layer = "Improvement_Codes_Lookup") 
propcodelu <- st_read(gdb, layer = "Property_Code_Lookup") 
plumblu <- st_read(gdb, layer = "Plumbing_Lookup")

#----------------------
# GDB sent 10/10 via USB
gdb2 <- "./DATA/data1.gdb"

taxlots <- st_read(gdb2, "taxlots_20191010")
footprints <- st_read(gdb2, "building_footprints_20191010")
st_layers(gdb2)

#----------------------
# GDB sent 11/21
gdb3 <- "./DATA/data_20191112.gdb"
st_layers(gdb3)

bli_constraints <- st_read(gdb3, "bli_constraints_all")
nbhd <- st_read(gdb3, "neighborhoods_no_overlap")

gdb4 <- "./DATA/tree_canopy.gdb"
st_layers(gdb4)

bli_constraints_v2 <- st_read(gdb4, "bli_constraints_v2_pts_run4")
```

### Take sample of taxlots
```{r}
begin <- as.Date("2015-01-01")
end <- as.Date("2019-01-01")

# Reformat SALEDATE column (save as date type so that we can
# do math on it)
taxlots$saledate <- as.Date(as.character(taxlots$SALEDATE), "%m/%d/%Y")

# Take time interval of taxlots we're interested in (5-years)
taxlots_pruned <- taxlots %>%
  filter(saledate > begin & saledate < end)

dim(taxlots_pruned) 

# Here, STATE_ID is the unique identifier
glimpse(taxlots_pruned)

# Grab keys to the lots we want for state and property ids
stateids <- taxlots_pruned %>%
  pull(STATE_ID)
propids <- taxlots_pruned %>%
  pull(PROPERTYID)

# YAY! They're sums below are both zero, meaning we have 1:1 keys!
sum(data.frame(table(taxlots_pruned$STATE_ID))$Freq > 1)
sum(data.frame(table(taxlots_pruned$PROPERTYID))$Freq > 1)
```

### Collapse footprints

```{R}


# Now we will try merging/collapsing footprints on this smaller
# subset of the entire data set, only homes/MFR that have sold in the last
# 5 years.

# grab only the foot prints associated with stateids in our sample
ftprints_pruned <- footprints %>%
  filter(STATE_ID %in% stateids)

# check if these ids uniquely identify the building footprints
multi_foot <- ftprints_pruned %>%
  lwgeom::st_make_valid() %>%
  group_by(STATE_ID) %>%
  mutate(n = n()) %>%
  filter(n > 1)

dim(multi_foot) # they do not

# Make collapsed footprints dataset called `allfeet`
allfeet <- ftprints_pruned %>% 
  lwgeom::st_make_valid() %>%
  dplyr::group_by(STATE_ID) %>%
  dplyr::summarise(totalsqft = sum(BLDG_SQFT, na.rm = T),
            yearbuilt = mean(YEAR_BUILT, na.rm = T),
            avgheight = mean(AVG_HEIGHT, na.rm = T),
            surfelev = mean(SURF_ELEV, na.rm = T),
            minheight = mean(MIN_HEIGHT, na.rm = T),
            maxheight = mean(MAX_HEIGHT, na.rm = T),
            volume = mean(VOLUME, na.rm = T),
            bldgtype = BLDG_TYPE[1],
            bldguse = BLDG_USE[1]) %>%
  st_drop_geometry()
dim(allfeet)

```


### Prune and reshape impsegcop
Impsegcop has our attached garage, patio, basement, attic, deck, variables among others. Reshape to get the square footage of each segment type. For properties that have multiple decks, attics, etc, the square footage was summed by type, so currently there is no way to distinguish between properties that have multiple attics or basements. We can think about whether proxying with a summed square footage is actually reasonable. 
```{r}
impsegcop$SegmentSqFt <- as.numeric(impsegcop$SegmentSqFt) # so we can eventually sum

isc_pruned <- impsegcop %>%
  filter(PropID %in% propids)
dim(isc_pruned)


sum(data.frame(table(isc_pruned$PropID))$Freq > 1)

# check if propids ids uniquely identify the building footprints
multi_isc <- isc_pruned %>%
  group_by(PropID, SegmentType) %>%
  mutate(n = n()) %>%
  filter(n == 1)

nrow(multi_isc)

# Second attempt to widen using dcast: works perfectly on 1:1 data
# Reshape using dcast. Set fun.aggregate to sum, which means that we 
# sum the square footage across multiple obs.
library(data.table)
impsegcop_wide <- dcast(setDT(isc_pruned), PropID ~ SegmentType,
              value.var = c("SegmentSqFt"),
              fill = 0,
              fun.aggregate = sum)

# Code below turns 0 meaning PropID uniquely identifies observations
sum(data.frame(table(impsegcop_wide$PropID))$Freq > 1)

```


### Prune and Reshape Impseg
We need the columns PlumbingCode and Fire_place_Lookup from the impseg df. However, it appears that there are other value variables such as perimeter, neighborhood marketvalue, total area, etc. that could be useful for our analysis. 
```{r}
glimpse(impseg)
levels(impseg$Plumbing_Code)
levels(impseg$Fire_Place_Code)
levels(impseg$Seg_Type)

# change from factor to numeric
impseg$Perimeter_feet <- as.numeric(impseg$Perimeter_feet)
impseg$Neighborhood_Market_Value_Percent <- as.numeric(impseg$Neighborhood_Market_Value_Percent)

is_pruned <- impseg %>%
  filter(PropertyID %in% propids)
dim(is_pruned) #took roughly 1% of the properties in impseg
dim(impseg)

is_pruned$PropertyID <- droplevels(is_pruned$PropertyID)

# there are 6901 multi observations 
# multi_is is not essential to create the reshaped df
multi_is <- is_pruned %>%
  group_by(PropertyID, Seg_Type) %>%
  mutate(n = n()) %>%
  filter(n > 1)

# most of the information in plumbing code is
# stored in the segment type: "MA"

# ceiling height, number of rooms, condition code,
# length, height is useless

# Q: what is interior_component_code?

#--------------------------------------------
# Using base r because dplyr code took too long

# Take only observations for which Plumbing_Code is non-missing
bath <- is_pruned[!is.na(is_pruned$Plumbing_Code),]
bath <- bath %>% dplyr::select(PropertyID, Plumbing_Code, Seg_Type)

bath$Seg_Type <- droplevels(bath$Seg_Type)
table(bath$Seg_Type) # again, most of the bathrooms are in MA

# There are 1657 properties with more than one "MA" = "Main" segment
# The code below tells us which properties these are...
is_pruned %>%
  filter(Seg_Type == "MA") %>%
  group_by(PropertyID, Seg_Type) %>%
  mutate(n = n()) %>%
  filter(n > 1) %>%
  select(Fire_Place_Code, PropertyID, Plumbing_Code)

# ---------------------------------
# Which segment types contain the fireplace code?
# `fire` is a data frame of all nonmissing Fire_Place_Code observations
fire <- is_pruned[!is.na(is_pruned$Fire_Place_Code),]
fire <- fire %>% dplyr::select(PropertyID, Fire_Place_Code, Seg_Type)

fire$Seg_Type <- droplevels(fire$Seg_Type)
table(fire$Seg_Type) # again, most of the fire info is in MA
# ---------------------------------

# Change from factor to numeric in order to eventually summarise()
is_pruned$Perimeter_feet <- as.numeric(is_pruned$Perimeter_feet)
is_pruned$Neighborhood_Market_Value_Percent <- as.numeric(is_pruned$Neighborhood_Market_Value_Percent)

# Generate the reshaped data frame, and save as all.is: "all.impseg"
all.is <- is_pruned %>% 
  group_by(PropertyID) %>%
  summarise(totalarea = sum(Total_Area, na.rm = T),
            mktval = mean(Market_Value, na.rm = T),
            totalAdjPct = mean(Total_Adjustment_Percent, na.rm = T),
            nbhdMktVal = mean(Neighborhood_Market_Value_Percent, na.rm = T),
            Perimeter_feet = sum(Perimeter_feet, na.rm = T),
            effarea = sum(Effective_Area, na.rm = T))
dim(all.is) # dropped to 33290 properties

```

#### Add bath & fire columns to `all.is` separately
Group by propertyID then collapse all Plumbing_Codes so
PropertyID = 1, Plumbing_Code = "FB1"
PropertyID = 1, Plumbing_Code = "HB2"  -->  PropertyID = 1, bath = "FB1|HB2"
```{r}
baths <- bath %>% group_by(PropertyID) %>%
  summarise(bath = paste0(Plumbing_Code, 
                          collapse = "|"))

fires <- fire %>% group_by(PropertyID) %>%
  summarise(fireplace = paste0(unique(Fire_Place_Code), collapse = "|"))

all.is <- left_join(all.is, baths, by = "PropertyID")
all.is <- left_join(all.is, fires, by = "PropertyID") 
```


## JOINS
### Left join footprints -> taxlots
```{r}
dim(taxlots_pruned)
dim(allfeet)

testjoint <- left_join(taxlots_pruned, allfeet, by = "STATE_ID")
#testjoint2 <- st_intersection(taxlots_pruned, allfeet)
dim(testjoint)
#dim(testjoint2)
```

### Left join impsegcop_wide to taxlots
```{r}
impsegcop_wide$PROPERTYID <- impsegcop_wide$PropID # rename variable to join
# by same id
m <- left_join(taxlots_pruned, impsegcop_wide, 
               by = "PROPERTYID")
m2 <- left_join(testjoint, impsegcop_wide, 
                by = "PROPERTYID") 
dim(m2)
dim(taxlots_pruned)
```

### St_intersection school to taxlots

One problem with an st_intersection is some lots are divided by the school catchment area boundaries, resulting in non-unique STATE_IDs in `testjoint3`. The st_intersection adds a second observation if it a tax lot is partially within catchment area 1 and partially within catchment area 2.

This is the reason the number of observations rose after the intersection. 

```{r}
# Naive st_intersection 
testjoint3 <- st_intersection(m2, school)

# Save multiple STATE_ID obs in `schzone`
schzone <- testjoint3 %>%
  group_by(STATE_ID) %>%
  mutate(n = n()) %>%
  filter(n > 1)

# We can see that adding the number of unique stateIDs that are observed more than once
# to the old dimensions is equal to the number of rows in testjoint3.
nrow(m2) + length(unique(schzone$STATE_ID)) == nrow(testjoint3)

# Fix: choose a catchment area for multiple STATE_ID lots depicted below. 
schzone %>%
  arrange(STATE_ID) %>%
  select(contains("SCH"), Shape_Area, Shape_Area.1) %>%
  st_drop_geometry() %>%
  head() %>%
  kable() %>% 
  kable_styling(full_width = F)


# Choose based on percentage of lot within that catchment area
schzone$area.school <- st_area(st_geometry(schzone))
testjoint3$area.school <- st_area(st_geometry(testjoint3))

schzone %<>%
  group_by(STATE_ID) %>%
  mutate(max = max(area.school)) 

schzone.big <- schzone %>% # add containing containing max area by STATE_ID
  filter(as.numeric(max) == as.numeric(area.school)) 

schzone.small <- schzone %>%
  filter(as.numeric(max) != as.numeric(area.school)) 

schzone.big$STATE_ID == schzone.small$STATE_ID # this vector should all be true

# Use st_combine to meld the broken boundaries from schzone.small and schzone.big geometry sets.
# note: I did not use st_union(st_geometry(schzone.small), st_geometry(schzone.big)) because
# st_union() takes the cartesian union of both giving a much larger feature set than neccessary, 
# we only want the diagonals
for(r in 1:nrow(schzone.big)){
  st_geometry(schzone.big[r,]) <- st_combine(c(st_geometry(schzone.big)[r], 
               st_geometry(schzone.small)[r]))
}

# Now, combine the fixed geometries and catchment areas with the single-observation
# subset of `testjoint3`
single.school <- testjoint3 %>%
  group_by(STATE_ID) %>%
  mutate(n = n(),
         max = NA) %>%
  filter(n == 1) # This is the right number of rows, 34426

# Row number check
nrow(schzone.big) + nrow(single.school) == nrow(taxlots_pruned)

testjoint3 <- rbind(schzone.big, single.school)
```


### Left join impseg to taxlots
```{r}
all.is$PROPERTYID <- all.is$PropertyID
testjoint4 <- left_join(testjoint3, all.is, by = "PROPERTYID")
dim(testjoint4)
```


### **NOT WORKING PROPERLY: Constraints to taxlots
Note that constraints are separated by taxlot but they are not identified by STATEID or PROPERTYID. We identify them using a spatial join with taxlots. 

```{r}
dim(testjoint4)
sum(data.frame(table(bli_constraints$STATE_ID))$Freq > 1)

# grab the keys off taxlots
slim_tax <- taxlots %>%
  select(STATE_ID, PROPERTYID)

# use the centroids in order to st_join
con_pt <- bli_constraints %>%
  st_centroid()

# join
identified_const <- st_join(con_pt, slim_tax)
```


### Distance to CBD 
Using City Hall as the CBD. Right now using Euclidean distance, might wanna go back and use street networks as well to compare. 

```{r}
#creating city hall coordinate data frame
cityhall_coord <- data.frame(
                 place = c("City Hall"),
                 longitude = (-122.678904),
                 latitude = (45.514858))

#creating list of distance measures
cityhall <- st_as_sf(cityhall_coord, coords = c("longitude", "latitude")) %>%
  st_set_crs(4326) %>%
  st_transform(2913)

#adding column to taxlots_pruned
taxlots_pruned <- taxlots_pruned %>%
  mutate(dist_cityhall = as.numeric(st_distance(taxlots_pruned, cityhall, which = "Euclidean")))

```


* * *
## Write to shapefile
```{R}
library(sf)
st_write(taxlots, "DATA/thesis_data1-11.shp")
```