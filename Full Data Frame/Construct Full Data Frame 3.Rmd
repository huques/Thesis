---
title: "Construct Full Data Frame 3"
output: pdf_document
---


### 0. Table of Contents
1. Load Packages
2. Set Pathnames and Load Databases
3. Take Sample of Taxlots
4. Complete Neighborhood Walkscore
5. Neighborhood Fixed Effects
6. Percent Vacant Properties within 200 ft
7. Schools 
8. Distance to City Hall (Central Business District)
9. Distance to Urban Growth Boundary
10. Collapse Footprints
11. Prune and Reshape Impsegcop
12. Prune and Reshape Impseg
13. Accessory Dwelling Unit Dummy
14. Percent of Lot Covered by Canopy
15. Constraints
16. conFld100 - Building Footprint
17. Spatial Quadrants
18. Partial Constraints
19. Zoning Changes
20. Export Full Data Frame


### 1. Load packages
```{r}
library(data.table)
library(here)
library(magrittr)
library(readxl)
library(sf)
library(sp)
library(stringr)
library(tidyverse)
```


### 2. Set Pathnames and Load Databases
```{r}
# GDB sent 10/29 via email
gdb <- here::here("DATA", "data2.gdb")
impsegcop <- st_read(gdb, layer = "CoP_OrionImprovementSegment")
gisimpcop <- st_read(gdb, layer = "CoP_GISImprovement")
impseg <- st_read(gdb, layer = "imp_segments")
school <- st_read(gdb, layer = "school_attendance_areas")

# GDB sent 10/10 via USB
gdb2 <- here::here("DATA", "data1.gdb")
taxlots <- st_read(gdb2, "taxlots_20191010")
footprints <- st_read(gdb2, "building_footprints_20191010")

# GDB sent 11/12 via email
gdb3 <- here::here("DATA", "data_20191112.gdb")
bli_constraints <- st_read(gdb3, "bli_constraints_all")
nbhd <- st_read(gdb3, "neighborhoods_no_overlap")

# GDB sent 11/22 via email
gdb4 <- here::here("DATA", "tree_canopy.gdb")
bli_constraints_v2 <- st_read(gdb4, "bli_constraints_v2_pts_run4")

# SHP sent 11/25 via email
ugb <- st_read(here::here("DATA", "ugb",
                              "ugb.shp"))

# SHP sent 11/22 via email
zoningaug2014 <- st_read(here("DATA", "Zoning_History",
                              "Zoning_2014_Aug_pdx.shp"))
zoningfeb2014 <- st_read(here("DATA", "Zoning_History",
                              "Zoning_2014_Feb_pdx.shp"))
zoningaug2015 <- st_read(here("DATA", "Zoning_History",
                              "Zoning_2015_Aug_pdx.shp"))
zoningfeb2015 <- st_read(here("DATA", "Zoning_History",
                              "Zoning_2015_Feb_pdx.shp"))
zoningaug2016 <- st_read(here("DATA", "Zoning_History",
                              "Zoning_2016_Aug_pdx.shp"))
zoningfeb2016 <- st_read(here("DATA", "Zoning_History",
                              "Zoning_2015_Feb_pdx.shp"))
zoningaug2017 <- st_read(here("DATA", "Zoning_History",
                              "Zoning_2017_Aug_metro.shp"))
zoningaug2018 <- st_read(here("DATA", "Zoning_History",
                              "Zoning_2018_Aug_pdx.shp"))
zoningfeb2018 <- st_read(here("DATA", "Zoning_History",
                              "Zoning_2018_Feb_pdx.shp"))

# XLSX sent 2/04 via email 
crosswalk <- read_xlsx(here::here("DATA", "zoning_crosswalk.xlsx"))
crosswalk %<>%
  rename(sale_zone = `Base Zone`)

# GDB sent 2/10 via email
gdb5 <- here::here("DATA", "canopy_20200210.gdb")
canopy <- st_read(gdb5, "canopy_taxlot_intersect")

# GDB 2/11 from PortlandMaps
walk_gdb <- here::here("DATA", "Complete_Neighborhoods_Scoring_Surface")
walk <- st_read(walk_gdb, 
           layer = "Complete_Neighborhoods_Scoring_Surface")

# GDB sent 2/13 via email 
intersectionz <- st_read(here::here("DATA", "constraint_layers.gdb"),
                         "Intersectionz")

# Source: GDB created in GIS using FEMA map + building footprints: 
# FEMA map - https://www.portlandmaps.com/arcgis/rest/services/Public/Hazard/MapServer/1
ftfld_ids <- st_read(here("DATA", "ft_fld.gdb"),
                     layer = "ft_floodplain")

# Source: https://gis-pdx.opendata.arcgis.com/datasets/portland-administrative-sextants
sex <- here("DATA", "Portland_Administrative_Sextants",
            "Portland_Administrative_Sextants.shp") %>% 
  sf::st_read()


```


### 3. Take Sample of Taxlots
```{r}
begin <- as.Date("2015-01-01")
end <- as.Date("2019-01-01")

# Change SALEDATE column to date object
taxlots$saledate <- as.Date(as.character(taxlots$SALEDATE), "%m/%d/%Y")

# Filter by time interval we're interested in (5-years)
taxlots_pruned <- taxlots %>%
  filter(saledate > begin & saledate < end)

# Grab keys to the lots we want for state and property ids
stateids <- taxlots_pruned %>%
  pull(STATE_ID)
propids <- taxlots_pruned %>%
  pull(PROPERTYID)


#-------------------------------------------------------------------------------
# define repeat observation function -- used after each join as a check 
n_repeats <- function(data, id_var){
  id_var <- enquo(id_var)
  keys <- data %>%   # make df of id variables
    pull(!!id_var)
  table(keys) %>%    # turn df into table so each row a is an id
    data.frame() %>% # turn into df so we get state id and the Freq, or # of times it appears
    filter(Freq > 1) %>%  # find those that appear multiple times
    count() %>%   # count the no. of duplicates
    pull(n) %>%   # return as integer (instead of tibble)
    as.character() 
}
```


### 4. Complete Neighborhood Walkscore

```{r}
# Transform crs from 4326 to 2913
walk %<>% 
  st_transform(2913) %>%
  dplyr::select(CN_score) # note that we're dropping all other variables that came with this df

# join to dataframe
fugly <- sf::st_join(st_centroid(taxlots_pruned), walk)
paste0("walkscore Join: ", n_repeats(fugly, STATE_ID)) %>% print()
```


### 5. Neighborhood Fixed Effects

```{r}
nbhd %<>% 
  dplyr::select(NAME)

# join to dataframe
fugly <- st_join(st_centroid(fugly), nbhd)
print(paste0("nbhd Join: ",  n_repeats(fugly, STATE_ID)))
```


### 6. Percent Vacant Properties within 200 ft

```{r}
# explicitly define the missing values in a factor level
taxlots$STATE_ID <- fct_explicit_na(taxlots$STATE_ID)

# df of unique obs -- 197,131 obs
vacancy_pruned <- taxlots %>%
  dplyr::select(STATE_ID, PRPCD_DESC, Shape) %>%
  group_by(STATE_ID) %>%
  mutate(n = n()) %>%
  filter(n == 1) 

# create vacant column
vacancy_pruned %<>% 
  mutate(VACANT = case_when(PRPCD_DESC == "VACANT LAND" ~ 1,
                            TRUE ~ 0))

# creates a buffer called buffer_dist
# 1 ft = 0.3048 meters
conv <- 0.3048
ft <- 200
buffer_dist <- ft * conv

# creates buffer of size `buffer_dist` around buffy
buffy <- taxlots_pruned %>%
  rename(ShapeBuffy = Shape) %>%
  st_buffer(buffer_dist)

# join buffy and vacancy_pruned columns 
vacant_join_buffy <- st_join(buffy, vacancy_pruned, left = TRUE)

# calculates percent vacant houses in buffer
# taking out na's when calcing percent vacant
vacant_var <- vacant_join_buffy %>%
  st_drop_geometry() %>%
  dplyr::group_by(STATE_ID.x) %>%
  dplyr::mutate(n = n(),
         VACANT = VACANT*1) %>%
  dplyr::filter(!is.na(VACANT)) %>% 
  dplyr::summarize(percent_vacant = sum(VACANT)/n[1]) %>%
  dplyr::rename(STATE_ID = STATE_ID.x)

# join to dataframe 
fugly <- left_join(fugly, vacant_var, by = "STATE_ID")
print(paste0("vacant Join: ",  n_repeats(fugly, STATE_ID)))
rm(vacant_var, vacant_join_buffy, buffy, vacancy_pruned)
```


### 7. Schools

One problem with an st_intersection is some lots are divided by the school catchment area boundaries, resulting in non-unique STATE_IDs. The st_intersection adds a second observation if it a tax lot is partially within catchment area 1 and partially within catchment area 2.

This is the reason the number of observations rose after the intersection. 

```{r}
school %<>% 
  dplyr::select(-c(Shape_Leng, Shape_Length, Shape_Area))

# join to dataframe
fugly <- st_join(st_centroid(fugly), school)
print(paste0("school Join: ",  n_repeats(fugly, STATE_ID)))
rm(school)
```


### 8. Distance to City Hall (Central Business District)

```{r}
# grab lat and long from google maps
cityhall <- data.frame(place = "City Hall",
                       long = -122.679103,
                       lat = 45.515000) %>%
  st_as_sf(coords = c("long", "lat")) %>% # reformat from df to sf object
  st_set_crs(4326) %>%   # Set coordinate system
  st_transform(2913)
  
  
# HERE IS THE ERROR
fugly$dist_cityhall <- st_distance(cityhall, fugly, 
                                   which = "Euclidean")[1,]
rm(cityhall)
```


### 9. Distance to Urban Growth Boundary

This approach calculates distances using the centroids of MULTIPOLYGON taxlots. So, in the process, the st_geometry() attribute of the taxlot spatial data frame is changed from polygons to points. But the geometry can be reset to MULTIPOLYGONS afterward.

```{r, warning = FALSE}
# Transform UGB shapefile
ugb %<>% 
  st_transform(2913) %>% 
  st_cast(., "MULTILINESTRING")

# Convert to sp object since we use the rgeos::NearestPoints function that requires this
# data type
ugb.sp <- as_Spatial(ugb)


# Pull taxlot polygons & calculate centroids
centroids <- st_geometry(fugly)
centroids.sp <- as_Spatial(centroids)

# gNearestPoints returns vector of nearest point on taxlot (the centroid) 
# and the nearest point on the ugb. We take the ugb point, the second item in the list.

# Initialize empty list
nearest_points <- list(NA, nrow(fugly))

# call gNearestPoints over all observations in `taxlots` to return list of point geometries
for(i in 1:nrow(fugly)){
  nearest_points[i] <- st_as_sf(rgeos::gNearestPoints(centroids.sp[i,], ugb.sp)[2,])
}

# Combine/"unlist" the point geometries
nearest_points <- do.call(c, nearest_points)

# When given two vectors, st_distance(a, b) returns distance between all pairs of points in a and a.
# ex. if a = c(1,2,3) b = c(0, 9, 8). then st_distance(a, b) = (1, 8, 7, 2, 7, 6, 3, 6, 5)
# mapply() loops over nearest_points and centroids simultaneously so usign the above a, b, 
# we end up with (1,7,5)
fugly$dist_ugb <- mapply(FUN = st_distance, nearest_points, centroids)
rm(nearest_points, ugb.sp, ugb, centroids.sp, centroids)

```


### 10. Collapse Footprints

Now we will try merging/collapsing footprints on this smaller subset of the entire data set, only homes that have sold in the last 5 years.

```{r, warning = FALSE}
# grab only the footprints associated with stateids in our sample
ftprints_pruned <- footprints %>%
  filter(STATE_ID %in% stateids) %>%
  mutate(YEAR_BUILT = case_when(YEAR_BUILT == 2106 ~ 2016,
                   TRUE ~ as.numeric(YEAR_BUILT)))

# make YEAR_BUILT zeros into NA's so that they average together properly
ftprints_pruned$YEAR_BUILT[ftprints_pruned$YEAR_BUILT == 0] <- NA


# Make collapsed footprints dataset called `allfeet`
ftprints_pruned %<>% 
  st_drop_geometry() %>%
  dplyr::group_by(STATE_ID) %>%
  dplyr::summarise(totalsqft = sum(BLDG_SQFT, na.rm = T),
            yearbuilt = mean(YEAR_BUILT, na.rm = T),
            maxheight = max(AVG_HEIGHT, na.rm = T),
            avgheight = mean(AVG_HEIGHT, na.rm = T),
            surfelev = mean(SURF_ELEV, na.rm = T),
            minheight = mean(MIN_HEIGHT, na.rm = T),
            volume = mean(VOLUME, na.rm = T),
            n_units = sum(UNITS_RES, na.rm = T),
            n_buildings = n()) 

# Join to dataframe
fugly <- left_join(fugly, ftprints_pruned, 
               by = "STATE_ID")
print(paste0("feet Join: ",  n_repeats(fugly, STATE_ID)))
rm(ftprints_pruned)
```


### 11. Prune and Reshape Impsegcop

Impsegcop has our attached garage, patio, basement, attic, deck, variables among others. Reshape to get the square footage of each segment type. For properties that have multiple decks, attics, etc, the square footage was summed by type, so currently there is no way to distinguish between properties that have multiple attics or basements. We can think about whether proxying with a summed square footage is actually reasonable. 

```{r}
# Reshape using dcast. Set fun.aggregate to sum, which means that we
# sum the square footage across multiple obs.
impsegcop_wide <- impsegcop %>%
  dplyr::filter(PropID %in% propids) %>%
  dplyr::mutate(SegmentSqFt = as.numeric(SegmentSqFt)) 

impsegcop_wide <- dcast(setDT(impsegcop_wide), PropID ~ SegmentType,
              value.var = c("SegmentSqFt"),
              fill = 0,
              fun.aggregate = sum) %>%
  dplyr::rename(PROPERTYID = PropID)


# Join to dataframe
fugly <- left_join(fugly, impsegcop_wide, 
               by = "PROPERTYID")
print(paste0("fugly impsegcop Join: ",n_repeats(fugly, STATE_ID)))
rm(impsegcop_wide)
```


### 12. Prune and Reshape Impseg

We need the columns PlumbingCode and Fire_Place_Lookup from the impseg df. However, it appears that there are other value variables such as perimeter, neighborhood market value, total area, etc. that could be useful for our analysis. 

```{r}
is_pruned <- impseg %>%
  filter(PropertyID %in% propids)

#-------------------------------------------------------------------------------
#BATHROOMS

# Take only observations for which Plumbing_Code is non-missing
bath <- is_pruned %>%
  filter(!is.na(Plumbing_Code)) %>%
  dplyr::select(PropertyID, Plumbing_Code, Seg_Type) %>%
  dplyr::group_by(PropertyID) %>%
  dplyr::summarise(bath = paste0(Plumbing_Code, collapse = "|")) %>%
  dplyr::rename(PROPERTYID = PropertyID) %>%
  dplyr::ungroup()

# join to dataframe
fugly <- left_join(fugly, bath, by = "PROPERTYID")
print(paste0("fugly bath Join: ",  n_repeats(fugly, STATE_ID)))



#-----------------
# Recode bathrooms 
# Initialize columns: f.baths = total full baths, h.baths = total half baths
fugly$f_baths <- NA
fugly$h_baths <- NA

extractBaths <- function(string){
  if(is.na(string)){c(fb = NA, hb = NA)}
  else{
    str <- strsplit(string, "[[:punct:]]")[[1]]
    str <- sort(str)
    fb <- str[grepl("FB", str)]
    hb <- str[grepl("HB", str)]
    nfb <- sum(as.numeric(gsub("FB", "", fb)))
    nhb <- sum(as.numeric(gsub("HB", "", hb)))
    c(fb = nfb, hb = nhb)
  }
}

# Create 2 x 34480 matrix of number of bathrooms
bath_matrix <- sapply(fugly$bath, extractBaths)
fugly$f_baths <- bath_matrix[1,]
fugly$h_baths <- bath_matrix[2,]

rm(bath_matrix)

#-------------------------------------------------------------------------------
# FIREPLACES

# Which segment types contain the fireplace code?
# `fire` is a data frame of all nonmissing Fire_Place_Code observations

fire <- is_pruned %>% 
  filter(!is.na(Fire_Place_Code)) %>%
  dplyr::select(PropertyID, Fire_Place_Code, Seg_Type) %>%
  dplyr::group_by(PropertyID) %>%
  dplyr::summarise(fireplace = paste0(unique(Fire_Place_Code), 
                                      collapse = "|")) %>%
  dplyr::rename(PROPERTYID = PropertyID)

fugly <- left_join(fugly, fire, by = "PROPERTYID") 
print(paste0("Fugly fire Join: ",  n_repeats(fugly, STATE_ID)))

#------------------
# Recode fireplaces

# I chose to treat all the fireplaces as the same and count the number of fireplaces/hearth
# That is fireplaces coded as MD2 = MODULAR 2 and BK1 = BRICK 1.
# Did this because it seems reasonable to think that differing styles/types of fireplaces
# won't have a measurable effect on property values. Can come back 
# to this decision, & check out the firelu table. 

extractHearth <- function(string){
  if(is.na(string)){NA}
  else{
    str <- strsplit(string, "[[:punct:]]")[[1]]
    length(str)
  }
}

fugly$n_fireplaces <- sapply(fugly$fireplace, extractHearth)
```


### 13. Accessory Dwelling Unit Dummy

Not specified based on number of ADU's on a property. 

```{r}
# column (267352 obs) with unique PropID and ADU dummy
ADU <- gisimpcop %>%
  dplyr::select(ImpType, PropID) %>%
  count(PropID) %>%
  mutate(ADUdummy = ifelse(n == 1, "0", "1")) %>%
  dplyr::select(PropID, ADUdummy) %>%
  rename(PROPERTYID = PropID)

ADU <- ADU[-c(1),]

# join to dataframe 
fugly <- left_join(fugly, ADU, by = "PROPERTYID")
print(paste0("ADU Join: ",  n_repeats(fugly, STATE_ID)))
rm(ADU)
```


### 14. Percent of Lot Covered by Canopy

```{r}
# create new data frame in order to calculate total taxlot area
taxlot_areas <- fugly %>%
  rename(taxlot_area = Shape_Area) %>%
  dplyr::select(STATE_ID, taxlot_area) %>% 
  st_drop_geometry()

# Collapse canopy by STATE_ID and generate canopy coverage ratios
canopy <- canopy %>%
  # filter for just those STATE_IDs in the taxlots pruned data set
  dplyr::filter(STATE_ID %in% stateids) %>% 
  rename(canopy_area = Shape_Area) %>%
  # join the taxlot areas by state_id (for the denominator)
  dplyr::left_join(taxlot_areas, by = "STATE_ID") %>% 
  # dropped because we had many self-intersections when trying to summarize
  st_drop_geometry() %>% 
  dplyr::group_by(STATE_ID) %>% 
  # take the first element in taxlot_area
  dplyr::summarise(pct_canopy_cov = sum(canopy_area) / taxlot_area[1], 
                   # save numerator and denominator separately
                   total_canopy_cov = sum(canopy_area), 
                   taxlot_area = taxlot_area[1]) 
                   # should end up with 33387 observations

# join to dataframe
fugly <- left_join(fugly, canopy, by = "STATE_ID")
print(paste0("Canopy Join: ", n_repeats(fugly, STATE_ID)))
rm(canopy)
```


### 15. Constraints

```{r}
# Define dplyr helper functions
genDummy <- function(x){ifelse(is.na(x), 0, 1)}
setToOne <- function(x){ifelse(x > 1, 1, x)}

# Change <NA>, "True" instances to 0, 1 for all 204,000+ properties
non_id_constraints <- bli_constraints_v2 %>%
  dplyr::select(contains("con")) %>%
  mutate_if(is.factor, genDummy)

st_geometry(non_id_constraints) <- st_geometry(bli_constraints)

# This join increases number of observations because sometimes there are several observations
# in non_id_constraints that are within the confines of a single taxlot polygon
firstjoin <- st_join(st_centroid(taxlots_pruned), non_id_constraints, 
                     left = TRUE)

# Collapse these observations so that we keep all the constraints as either 1 or 0 for each 
# property. Here, we're not worrying about partial constraints yet.
dumdum_constraints <- firstjoin %>%
  dplyr::group_by(STATE_ID) %>%
  dplyr::select(contains("con")) %>% 
  st_drop_geometry() 

# join to dataframe
fugly <- left_join(fugly, dumdum_constraints, by = "STATE_ID")
print(paste0("constraints Join: ", n_repeats(fugly, STATE_ID)))
rm(firstjoin, dumdum_constraints, non_id_constraints)
```


### 16. conFld100 - Building Footprint

```{r}
ftfld_ids %<>%
  dplyr::filter(STATE_ID %in% stateids) %>%
  pull(STATE_ID)

# join to dataframe
fugly %<>%
  mutate(conFld100_ft = ifelse(STATE_ID %in% ftfld_ids, 1, 0))
```


## 17. Spatial Quadrants

```{r}
sex %<>%
  st_transform(2913)

# join to dataframe
fugly <- st_join(st_centroid(fugly), sex) %>%
  dplyr::select(PREFIX, STATE_ID) %>%
  st_drop_geometry() %>%
  dplyr::left_join(fugly, by = "STATE_ID") %>%
  rename(sextant = PREFIX)
```


### 18. Partial Constraints

```{r}
partial <- intersectionz %>%
  dplyr::filter(STATE_ID %in% stateids) %>%
  dplyr::group_by(STATE_ID) %>%
  dplyr::mutate(pct_conFld100 = ifelse(conFld100 == "True", 
                                sum(Shape_Area, na.rm = T) / AREA[1], 0),
         pct_conFldway = ifelse(conFldway == "True", 
                                sum(Shape_Area, na.rm = T) / AREA[1], 0),
         pct_conWetland = ifelse(conWetland == "True", 
                                 sum(Shape_Area, na.rm = T) / AREA[1], 0),
         pct_conPovrly = ifelse(conPovrly == "True", 
                             sum(Shape_Area, na.rm = T) / AREA[1], 0),
         pct_conCovrly = ifelse(conCovrly == "True", 
                             sum(Shape_Area, na.rm = T) / AREA[1], 0))

partial <- partial %>%
  st_drop_geometry() %>%
  dplyr::group_by(STATE_ID) %>%
  dplyr::summarise(pct_conFld100 = pct_conFld100[1],
            pct_conPovrly = pct_conPovrly[1],
            pct_conCovrly = pct_conCovrly[1],
            pct_conWetland = pct_conWetland[1],
            pct_conFldway = pct_conFldway[1]) %>%
  dplyr::mutate(pct_conFld100 = ifelse(pct_conFld100 > 1, 1, pct_conFld100),
         pct_conFldway = ifelse(pct_conFldway > 1, 1, pct_conFldway),
         pct_conCovrly = ifelse(pct_conCovrly > 1, 1, pct_conCovrly),
         pct_conPovrly = ifelse(pct_conPovrly > 1, 1, pct_conPovrly),
         pct_conWetland = ifelse(pct_conWetland > 1, 1, pct_conWetland))

# Replace NA values with 0
partial[is.na(partial)] <- 0

# join to dataframe
fugly <- left_join(fugly, partial, by = "STATE_ID")
rm(partial)
```


### 19. Zoning Changes 

based on zoning code changes effective 5/24/20

```{r}
# create list and name items in the list
zonelist <- list(zoningaug2014 = zoningaug2014,
                 zoningaug2015 = zoningaug2015,
                 zoningaug2016 = zoningaug2016,
                 zoningaug2017 = zoningaug2017,
                 zoningaug2018 = zoningaug2018,
                 zoningfeb2014 = zoningfeb2014, 
                 zoningfeb2015 = zoningfeb2015,
                 zoningfeb2016 = zoningfeb2016,
                 zoningfeb2018 = zoningfeb2018)

# creates a list `zonelist` with colnames modified
for(i in 1:length(zonelist)){
  name <- names(zonelist)[[i]]
  dat <- (zonelist)[[i]]
  string <- str_replace(name, "zoning", "_")
  colnames(dat) <- paste0(colnames(dat), string)
  st_geometry(dat) <- paste0("geometry", string)
  zonelist[[i]] <- dat
}

# creates a data frame with all dataframes joined using st_join
df <- st_join(st_centroid(taxlots_pruned), zoningfeb2018)

for(i in 1:(length(zonelist)-1)){
  df <- st_join(df, zonelist[[i]])
}

# Create new df with just the shorthand zoning variables across time
zones_over_time <- df %>%
  dplyr::select(contains("ZONE_"), STATE_ID, saledate) %>%
  dplyr::select(-contains("TMP", "CLASS")) %>%
  #select(-contains("DESC"))

zones_over_time %<>%
  dplyr::mutate(sale_zone = case_when(saledate >= as.Date("2014-02-01") & saledate < as.Date("2014-08-01") ~ ZONE_feb2014,
                                      saledate >= as.Date("2014-08-01") & saledate < as.Date("2015-02-01") ~ ZONE_aug2014,
                                      saledate >= as.Date("2015-02-01") & saledate < as.Date("2015-08-01") ~ ZONE_feb2015,
                                      saledate >= as.Date("2015-08-01") & saledate < as.Date("2016-02-01") ~ ZONE_aug2015,
                                      saledate >= as.Date("2016-02-01") & saledate < as.Date("2016-08-01") ~ ZONE_feb2016,
                                      saledate >= as.Date("2016-08-01") & saledate < as.Date("2017-08-01") ~ ZONE_aug2016,
                                      saledate >= as.Date("2017-08-01") & saledate < as.Date("2018-02-01") ~ ZONE_aug2017,
                                      saledate >= as.Date("2018-02-01") & saledate < as.Date("2018-08-01") ~ ZONE_feb2018,
                                      saledate >= as.Date("2018-08-01") ~ ZONE_aug2018)) %>%
  dplyr::mutate(sale_zone = as.character(sale_zone)) %>%
  dplyr::mutate(sale_zone = ifelse(is.na(sale_zone), 
                                   as.character(ZONE_aug2018), 
                                   sale_zone))

# Join use crosswalk to generate prop_type variable: MFR, SFR, mixed use
zones_over_time %<>%
  dplyr::left_join(crosswalk, by = "sale_zone") %>%
  st_drop_geometry() %>%
  dplyr::rename(prop_type = Simplified) %>%
  # below are older zones not matched with the crosswalk but clarified
  # in email from Nick, Al, and Barry
  dplyr::mutate(prop_type = case_when(sale_zone == "CM"|
                                        sale_zone == "CG"|sale_zone == "CN1"|
                                        sale_zone == "CN2"|sale_zone == "CS"|
                                        sale_zone == "CO1"|
                                        sale_zone == "CO2" ~ "Mixed Use",
                                      TRUE ~ prop_type)) %>%
  dplyr::select(-saledate)

# join to dataframe
fugly <- left_join(fugly, zones_over_time, by = "STATE_ID")
print(paste0("zone Join: ", n_repeats(fugly, STATE_ID)))
```


## 20. Export Full Data Frame

Creates a csv called `thesis-data.csv` that lives in the DATA folder. 

```{R}
fugly %>%
  select(-c(SHARED, Shape)) %>%
  write.csv(., here("DATA", "thesis-data.csv"))
```

