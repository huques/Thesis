---
title: "initial data cleaning"
output: pdf_document
---

## 1. Load packages
```{r}
library(tidyr)
library(dplyr)
library(sf)
library(stringr)
library(data.table)

datanames <- c("gisimpcop", "impsegcop", "gispropcop", "allpropcop", "segchar", "rollhist", "impseg", "salescop","school", "imps", "constraints", "rollhist_wide", "taxlots", "footprints")
datanames
```

## 2. Set pathnames and load databases
```{r}
# The geodatabase Nick sent via email on 10/29
gdb <- "DATA/data.gdb"

constraints <- st_read(gdb, layer = "bli_development_capacity")
gisimpcop <- st_read(gdb, layer = "CoP_GISImprovement")
impsegcop <- st_read(gdb, layer = "CoP_OrionImprovementSegment")
gispropcop <- st_read(gdb, layer = "CoP_GISProperty")
allpropcop <- st_read(gdb, layer = "CoP_AllProperties")
segchar <- st_read(gdb, layer = "Seg_Char")
rollhist <- st_read(gdb, layer = "roll_history")
rollhist_wide <- st_read(gdb, layer = "roll_history_wide")
#rollvals <- st_read(gdb, layer = "roll_values")
impseg <- st_read(gdb, layer = "imp_segments")
salescop <- st_read(gdb, layer = "CoP_OrionSalesHistory")
school <- st_read(gdb, layer = "school_attendance_areas")
imps <- st_read(gdb, layer = "improvements")

firelu <- st_read(gdb, layer = "Fireplace_Lookup")
segmentlu <- st_read(gdb, layer = "Segment_Type_Lookup")
imptypelu <- st_read(gdb, layer = "Imp_Type_Lookup")
impcodeslu <- st_read(gdb, layer = "Improvement_Codes_Lookup") 
propcodelu <- st_read(gdb, layer = "Property_Code_Lookup") 
plumblu <- st_read(gdb, layer = "Plumbing_Lookup")

#----------------------
# GDB sent 10/10 via USB
gdb2 <- "DATA/datanew.gdb"

taxlots <- st_read(gdb2, "taxlots_20191010")
footprints <- st_read(gdb2, "building_footprints_20191010")
```



## 3. Exploratory code 

### Column Names/Keys to join:
```{r}
# create function to extract all variable names as strings within a given layer
composed <- function(name){
  colnames(get(name))
}

# apply composed() over all layers (in `datanames`)
allvars <- lapply(datanames, composed)

names(allvars) <- datanames # give the list clearer names

#------------------------------
# Function to search all of our variable names for a given a string 
findVar <- function(string, case_sensitive = F){
  bool <- grepl(string, unlist(allvars), ignore.case = !case_sensitive) 
  # lbool is a boolean vector denoting which vars contain the string
  unlist(allvars)[bool] # subset total list of varnames by bool & return it
}

findVar("sqft")
findVar("id")
# -------------------------------

# has prefix
segchar$PropertyID
rollhist$PropertyID
salescop$PropID
gisimpcop$PropID
impsegcop$PropID
gispropcop$PropID
impseg$PropertyID

# this does not have letter prefix
allpropcop$PropertyID

```

### Finding Carlton house...
```{r}
id <- "R122577"
gisimpcop %>% filter(PropID == id)
salescop %>% filter(PropID == id)
rollhist %>% filter(PropertyID == id)
gispropcop %>% filter(PropID == id)
segchar %>% filter(PropertyID == id) #turned nothing
impseg %>% filter(PropertyID == "R328259" | PropertyID == id) %>% group_by(PropertyID)
impsegcop %>% filter(PropID == id)

```


### Finding Wimbledons...
```{r}
id <- "R228329"
gisimpcop %>% filter(PropID == id) # shows 0 units, which is a problem
salescop %>% filter(PropID == id) 
rollhist %>% filter(PropertyID == id)
gispropcop %>% filter(PropID == id) # hmm property type is commercial?
segchar %>% filter(PropertyID == id) #turned nothing
impseg %>% filter(PropertyID == id) %>% group_by(PropertyID)
impsegcop %>% filter(PropID == id)

```

### Property Type: Residential, Mixed-use, Multifamily
```{r}
levels(gispropcop$PropertyType)
levels(constraints$GEN_USE)
levels(constraints$GEN_ZONE)
levels(constraints$REG_ZONE)
levels(constraints$NEWDESIG)
levels(imp$Imp_Type)
```

### Test joins:
```{r}
salescop$SaleDate <- as.Date(salescop$SaleDate)
summary(salescop$SaleDate)
n <- salescop %>% filter(SaleDate < as.Date("2019-12-01"))
# all dates are exactly the same at "9999-12-31" find out what this means
weirddates <- salescop %>% filter(SaleDate > as.Date("2019-12-01"))

# check out the date ranges
summary(weirddates$SaleDate)
summary(n$SaleDate)

nrow(weirddates) 
nrow(n)

# Number of observations in each 5-year interval
for(year in 2010:2019){
  end <- paste0(year,"-12-01")
  begin <- paste0(year - 4,"-12-01")
  trim <- salescop %>% filter(SaleDate < as.Date(end) & SaleDate > as.Date(begin))
  invl <- paste(year - 4, year, sep = "-")
  print(paste(invl, nrow(trim), sep = ": "))
}
```


Choose 2014-2018 and merge across all data sets.
```{r}
year <- 2018
end <- paste0(year,"-12-01")
begin <- paste0(year - 4,"-12-01")
trim <- salescop %>% filter(SaleDate < as.Date(end) & SaleDate > as.Date(begin))

# Join:
merge1 <- left_join(trim, gisimpcop, by = "PropID")

head(merge1)
dim(merge1)
dim(trim) # there are more observations after the merge than before..
table(merge1$ImpType)

# are duplicate propertyIDs causing the increase in observations?
dupes <- data.frame(table(merge1$PropID))
sum(dupes$Freq > 1)
```


## Overlap sales history data with BLI constraints?
How many properties in the above sample are actually located within a constraint zone? 

Aside from mapping using the Master All Addresses choice from Portland Maps and overlaying the constraints and the properties using PropID in our sample, could try to construct a mapping thru keys we have. 

PropID -> StateID or TLID 

```{r}
keep <- grepl("(?i)id", unlist(allvars), perl=TRUE)
unlist(allvars)[keep]
```
From the above code, this may not be possible because all ID variables listed are not of the desired type. 

### NO LONGER NECESSARY: Grab ID dictionary from PDX maps
Using the Master_Address_Points excel spreadsheet, took the ID columns and saved as new excel file. Hopefully we can just bring these in and get correspondence between StateID and PropertyID.

```{r eval=FALSE, include=TRUE}
# how many properties have more than one constraint?
# inferred because some state ids occur more than once
tib <- data.frame(table(constraints$STATE_ID))
sum(tib$Freq > 1)
sum(tib$Freq == 1)

library(lwgeom)

multi_obs <- constraints %>%
  #st_cast("GEOMETRY") %>%
  lwgeom::st_make_valid() %>%
  group_by(STATE_ID) %>%
  dplyr::summarise(n = n()) %>%
  dplyr::filter(n > 1) %>% 
  dplyr::select(STATE_ID)

consubset <- constraints %>%
  dplyr::filter(STATE_ID %in% multi_obs$STATE_ID) %>%
  group_by(STATE_ID)

consubset[1:20,] %>%
  mapview()

library(readr)
dictID <- read_csv("Desktop/thesis/property-stateID.csv")

class(constraints$STATE_ID)
dictID$STATE_ID <- as.factor(dictID$STATE_ID)
const <- left_join(constraints, dictID, by = "STATE_ID")
colnames(constraints)

# Check how many duplicates we have for each ID (is there a 1:1 corresp
# between all the IDs). We hope the answer is yes, but it's more likely
# to be no
sum(data.frame(table(constraints$LOT_ID))$Freq > 1) #gives all duplicates on LOT_ID
sum(data.frame(table(constraints$STATE_ID))$Freq > 1)
sum(data.frame(table(constraints$TLID))$Freq > 1)

# Check the ID dictionary (these checks don't guarantee 1:1 corresp)
sum(data.frame(table(dictID$PROPERTY_ID))$Freq > 1)
sum(data.frame(table(dictID$STATE_ID))$Freq > 1)

# look at properties that have both stateID and propertyID recorded
d <- dictID %>% 
  filter(!is.na(STATE_ID) & !is.na(PROPERTY_ID))
dim(d) # got rid of roughly 100k observations

# check if we have the same number of duplicates for each id

sum(data.frame(table(d$STATE_ID))$Freq > 1)
```

From the code below, we can see that there are 30k more unique STATEIDs than PROPERTYIDS for all of Portland (all maps containing both a state and a property id). 

It could be that StateID is coded as -_ _ _ _ _ and _ _ _ _ _, difference between new and old StateIDs

```{r}
# Number of unique ids
dim(data.frame(table(d$PROPERTY_ID)))
dim(data.frame(table(d$STATE_ID))) 

dim(data.frame(table(dictID$PROPERTY_ID)))
dim(data.frame(table(dictID$STATE_ID))) 

# How does stateid differ across property ids?
sum(grepl("-", d$STATE_ID))
sum(grepl(" ", d$STATE_ID))
```


### Setting up constraints
All of our constraint variables are polygons, and therefore just "True" or empty. So the properties in this dataset are only a subset of the total number of properties we will analyze.

```{r}
const <- grepl("con", colnames(constraints))
polys <- constraints[,const]
```

* * * 

## The following data frames need to be reshaped:
What are the unique identifiers in each?
```{r}
# 1. Sales History
sum(data.frame(table(salescop$PropID))$Freq > 1)

# 2. CoP_OrionImprovementSegment
sum(data.frame(table(impsegcop$PropID))$Freq > 1)

# 3. CoP_GISProperty
sum(data.frame(table(gispropcop$PropID))$Freq > 1)

# 4. CoP_GISImprovement
sum(data.frame(table(gisimpcop$PropID))$Freq > 1)

# 5. CoP_AllProperties - no prefix
sum(data.frame(table(allpropcop$PropertyID))$Freq > 1)

# 6. improvements 
sum(data.frame(table(imp$PropertyID))$Freq > 1)
max(data.frame(table(imp$PropertyID))$Freq) # gives max # of repeated prop IDs

# 7. Seg_Char, 
sum(data.frame(table(segchar$PropertyID))$Freq > 1)
max(data.frame(table(segchar$PropertyID))$Freq)

# 8. roll_values
sum(data.frame(table(rollvals$PropertyID))$Freq > 1)

# 9. impseg 
sum(data.frame(table(impseg$PropertyID))$Freq > 1)

# 10. rollhist 
sum(data.frame(table(rollhist$PropertyID))$Freq > 1)

# 11, footprints - uniquely identified by BLDG_ID!
sum(data.frame(table(segchar$BLDG_ID))$Freq > 1)

# 12. Constraints
sum(data.frame(table(constraints$TLID))$Freq > 1)

```


### RESHAPE LONG -> WIDE: Seg_Char, segchar
```{r}
subsegchar <- segchar[1:100,]

names <- colnames(segchar)
drop <- c("SegID","Structure_Num","PropertyID", "Segment_Num")
keep <- names[!names %in% drop]

# PropertyID identifies a row to cast multiple columns upon
# the formula LHS ~ RHS must uniquely identify an observation in the long form, otherwise 
# the aggregation function defaults to counts.
segchar_wide <- dcast(setDT(segchar), PropertyID ~ Structure_Num + Segment_Num, value.var=c(keep))

sum(data.frame(table(gisimpcop$PropertyID))$Freq > 1)

```


### RESHAPE LONG -> WIDE: Improvements, imp
Reshapes a smaller version of `imp` for speed.
```{r}
subimp <- imp[1:100,]

# this chunk removes empty columns: "Not_Used2", "Not_Used4", etc.
names <- colnames(imp)
notused <- colnames(imp)[grepl("Not_Used", colnames(imp))]
notid <- names[grepl("Not_Identified", names)]
for(n in notid){
  if(sum(!is.na(imp[n]))==0){
    notid <- setdiff(notid, n)
  }
}
drop <- c(notused, notid, "ImpID","PropertyID")
keep <- names[!names %in% drop]


# propertyID and structure_num uniquely id observations in `imp`
imp_wide <- dcast(setDT(subimp), PropertyID ~ Structure_Num, value.var=c(keep))
```


### RESHAPE LONG -> WIDE: Roll_history
```{r}
subrollhist <- rollhist[1:100,]
names <- colnames(subrollhist)

drop <- c("Roll_Num","PropertyID")
keep <- names[!names %in% drop]
rollhist_wide <- dcast(setDT(subrollhist), PropertyID ~ year, value.var=c(keep))
```

### RESHAPE LONG -> WIDE: Imp_segments, impseg 
```{r}
# Reshaping impseg
multi_obs <- impseg %>%
  group_by(PropertyID) %>%
  summarise(n = n()) %>%
  filter(n > 1) %>% 
  pull(PropertyID)

# convert factor to numeric variables
impsegcop2 <- as.data.frame(lapply(impsegcop, function(x) as.numeric(as.character(x))))

impsegcop2$PropID <- impsegcop$PropID
impsegcop2$SegmentType <- impsegcop$SegmentType



test <- impsegcop2 %>% 
  dplyr::filter(PropID == "R143341") %>%
  pivot_wider(names_from = SegmentType, values_from = SegmentSqFt) %>%
  group_by(PropID) %>%
  summarize(mainsqft = sum(MAIN, na.rm = T),
            )

# Mutate another column counting number of times we see same segment
# type associated with same property
multi_type <- impsegcop2 %>%
  group_by(PropID, SegmentType) %>%
  summarize(n = n())

# Gather all weird  multi property ID, multi segment type observations
drop <- multi_type %>%
  group_by(PropID, SegmentType) %>%
  filter(n > 1) %>%
  pull(PropID)

# drops the weird multi observations
impsegcop_dropped <- impsegcop2 %>%
  filter(!PropID %in% drop)

# try salma's melting code
test1 <- melt(impsegcop_dropped, id = c("PropID", "SegmentType"), variable = SegmentSqFt)
test1 <- dcast(test1, PropID ~ SegmentType)

# vector of variable names to loop over
segcolumns <- levels(impsegcop$SegmentType)
segcolumns <- segcolumns[c(-1)]

impsegcop_dropped <- impsegcop_dropped[1:100,] %>%
    pivot_wider(names_from = SegmentType, values_from = SegmentSqFt)

# One method to reshape/rename impsegcop
impsegcop_dropped <- impsegcop_dropped %>%
  group_by(PropID) %>%
  summarise(main = sum(MAIN, na.rm = T),
            finattic  = sum(`FIN ATTIC`, na.rm = T),
            unfattic = sum(`UNF BSMT`, na.rm = T),
            built_in_gar = sum(`BUILT-IN GARAGE`, na.rm = T),
            #encporch = sum(`ENC PORCH`, na.rm = T),
            #covdeck = sum(`COV DECK`, na.rm = T),
            #bsmtgar = sum(`BSMT GAR`, na.rm = T),
            unfbsmt = sum(`UNF BSMT`, na.rm = T),
            finbsmt = sum(`FIN BSMT`, na.rm = T))
            #breezeway = sum(`BREEZEWAY`, na.rm = T))
              
            
impsegkeep <- c("PropertyID", "Segment_Num", "SegID", "Seg_Type", "Plumbing_Code", "Fire_Place_Code", "Number_of_Rooms", "Condition_Code") 
newimpseg <- impseg(impsegkeep)

names <- colnames(newimpseg)
drop <- c("Segment_Num","Seg_Type", "SegID", "PropertyID") #no need to be replicated
keep <- names[!names %in% drop] #things being replicated
subimpseg <- impseg[1:100,] #only ran first 100 for speed

impseg_wide <- dcast(setDT(subimpseg), PropertyID ~ Segment_Num, value.var=c(keep))



```


### RESHAPE LONG -> WIDE: CoP_AllProperties, allpropcop 
```{r}
names <- colnames(allpropcop)
drop <- c("RollYear", "PropertyID") #no need to be replicated
keep <- names[!names %in% drop] #things being replicated
suballpropcop <- allpropcop[1:100,] #only ran first 100 for speed

allpropcop_wide <- dcast(setDT(suballpropcop), PropertyID ~ RollYear, value.var=c(keep))
```


### RESHAPE LONG -> WIDE: CoP_OrionImprovementSegment, impsegcop 
```{r}
names <- colnames(impsegcop)
subimpsegcop <- impsegcop[1:100,]
impsegcop_wide <- dcast(setDT(subimpsegcop), PropID ~ SegmentNbr, value.var = c("SegmentSqFt", "SegmentType"))
```


### RESHAPE LONG -> WIDE: CoP_GISImprovement, gisimpcop
* Needs fixing--apply different technique to this..
```{r}
names <- colnames(gisimpcop)
drop <- c("PropertyID", "PropID", "YearBuilt", "TaxYear") #no need to be replicated
keep <- names[!names %in% drop] 
subgisimpcop <- gisimpcop[1:100,]
gisimpcop_wide <- dcast(setDT(subgisimpcop), PropID ~ YearBuilt, value.var = c(keep))
```


### RESHAPE LONG -> WIDE: roll_values, rollvals
```{r}
names <- colnames(rollvals)
drop <- c("Segment_Num","Structure_Num","Seg_Type", "SegID", "PropertyID") #no need to be replicated
keep <- names[!names %in% drop] #things being replicated
subrollvals <- rollvals[1:100,] #only ran first 100 for speed

rvs <- dcast(setDT(subrollvals), PropertyID ~ year, value.var=c(keep))
```


### RESHAPE: CoP_GISImprovement, gisimpcop
```{r}
# 11/14: Code from Nick - finding property IDs with multiple observations
multi_obs <- gisimpcop %>%
  group_by(PropID) %>%
  summarise(n = n()) %>%
  filter(n > 1) %>% 
  select(PropID)
multi_obs <- multi_obs$PropID

repeat_obs <- gisimpcop %>% 
  filter(PropID %in% multi_obs) %>%
  group_by(PropID)
```


### Function to split data frames by wanted property type
```{r}
levels(gisimpcop$ImpType)

# convert repeat_obs tibble to a data frame
repeat_obs <- as.data.frame(repeat_obs)

ids <- as.character(unique(repeat_obs$PropID)) # all property ids associated with
# more than one observation


wanted.imp.types <- c("6PX", "7PX", "CND", "MFS", "MFR", "ADUA", "CAMEN", "CAPT", "Cbase", "CC", "CCC", "M", "MFG", "MFL", "MFS", "MHP", "MPX", "RCU", "ROW", "SFR", "TPX")

split <- function(df, id){
  df_segment <- df %>% 
    filter(PropID == id)
  if(any(df_segment$ImpType %in% wanted.imp.types)){
    return(df_segment)
  }
  else{
    return(NA)
  }
}

frames <- lapply(ids, split, df = repeat_obs)

# remove the missing data frames
frames <- frames[!is.na(frames)]

# bind the mini dfs together
repeat_obs2 <- bind_rows(frames)

taxlots %>% filter(PROPERTYID == "R148319")

footprints %>% filter(STATE_ID == "1S2E19BB 15700")
```




* * * 

# Geometry merges

### School catchment area to taxlots
```{r}
# Filter just the Carlton house
carlton <- taxlots %>% 
  filter(grepl("6728 SE CARLTON", SITEADDR))

test <- st_intersection(carlton, school)
test %>%
  select(STATE_ID, OWNER1, BLDGVAL1, SITEADDR, HIGH_SCH, MIDDLE_SCH, ELEM_SCH)
```

#### [Aside: some taxlots are not 1 row:1 PROPERTYID]
The observations below need to be looked at more carefully. StateID does not have the same problem.

```{r}
ind <- data.frame(table(taxlots$PROPERTYID))$Freq > 1
multi.obs <- taxlots$PROPERTYID[ind]

icky <- taxlots %>% 
  filter(PROPERTYID %in% multi.obs)

head(icky) %>% select(RNO, STATE_ID, SITEADDR, PRPCD_DESC)
```


### Collapse Footprints by STATEID
Suppose there are n_i building footprints associated with a particular STATEID or property. The for loop below loops over all STATEIDs and the n_i polygons chunked with property i. 

* Assumes there are no overlapping building footprints
* not yet working 11/14

```{r}
sum(data.frame(table(footprints$STATE_ID))$Freq > 1)

# Remove the geometry & copy the STATE_ID column from footprints
footprints %>% 
  select(STATE_ID, Shape, Shape_Area, Shape_Length)

footprints %>%
  group_by(STATE_ID) %>%
  st_union()

footprints %>% 
  filter(is.na(STATE_ID))

geom = list()
for(i in 1:nrow(pol)) {
  geom[[i]] = st_union(pol[pol[i, ], ])
}
geom = do.call(c, geom)

st_union(test$Shape)
```


### Merge impsegcop_wide to taxlots: Try running without subsetting impseg and impsegcop!
Merge 1. Impsegcop_wide has the variables Attic, Garage, Patio, and the square footages associated with each. So we left_join these characteristics to the taxlots by PropertyID. 

Merge 2. Impseg_wide to taxlots. The df impseg_wide contains our fireplace and bathroom variables.

Merge 3. School catchment area to taxlots

```{r}
impsegcop_wide$PROPERTYID <- impsegcop_wide$PropID 
impseg_wide$PROPERTYID <- impseg_wide$PropertyID 

# add variable 
# PROPERTYID to the impsegwide_cop df, so we can join by consistent name

# Merge 1. impsegcop_wide
merged <- left_join(taxlots, impsegcop_wide, by = "PROPERTYID")
glimpse(merged)

# Merge 2. impseg_wide
merged <- left_join(taxlots, impseg_wide, by = "PROPERTYID")
glimpse(merged)

# Merge 3.  SCHOOL CATCHMENT AREA
merged <- st_intersection(merged, school)
glimpse(impsegcop_wide)
```















